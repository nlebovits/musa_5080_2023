---
title: "Predicting Home Sale Price in Philadelphia"
subtitle: "MUSA 508 Midterm"
author: "Akira di Sandro and Nissim Lebovits"
date: today
format: 
  html:
    embed-resources: true
    toc: true
    theme: flatly
    code-fold: true
    code-summary: "Show the code"
editor: source
execute:
  warning: false
  error: false
  messages: false
  echo: true
  cache: false
---

## Summary

## Introduction
```{r setup}
library(tidyverse)
library(olsrr)
library(sf)
library(caret) # add dummy vars
library(tmap)
library(fastDummies)
library(tidycensus)
library(sfdep)
library(curl)
library(zip)
library(rsgeo)
library(janitor)
library(spatstat)
library(maptools)
library(terra)
library(ggthemr)

tmap_mode('view')
options(tigris_use_cache = TRUE)
ggthemr('flat')

crs <- "epsg:2272"

set.seed(42)

```
## Methods

### Data Sources

### Data Wrangling
```{r data wrangle}
phl_path <- "https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson"
phl <- st_read(phl_path, quiet = TRUE) %>%
          st_transform(crs = crs)

### base data-----------------------------------------------
data_path <- ("data/2023/studentData.geojson")
data <- st_read(data_path, quiet = TRUE)


drop <- c("objectid", "assessment_date", "beginning_point", "book_and_page", "category_code", 
          "cross_reference", "date_exterior_condition", "house_number", "location", "owner_1", 
          "owner_2", "parcel_number", "recording_date", "registry_number", "sale_date",
          "mailing_address_1", "mailing_address_2", "mailing_care_of", "mailing_zip", "mailing_street", 
          "mailing_city_state", "building_code", "geographic_ward", "state_code", "street_code", 
          "street_name", "street_designation", "street_direction", "musaID", "census_tract", "suffix",
          "zip_code", "building_code_new", "year_built_estimate", "pin", "toPredict", "unit", "exempt_land",
          "building_code_description"
          )

to_cat <- c("category_code_description", "garage_type")

data <- data %>%
          mutate(non_resident_owner = mailing_address_1 == mailing_street) %>%
          select(-drop) %>%
          mutate_at(to_cat, as.character) %>% 
          # mutate(house_extension = as.numeric(house_extension)) %>% # for some reason, this *really* fucks up the model
          st_transform(crs = crs) %>%
          filter(sale_price > 1) %>% #need to filter for realistic sale prices, per https://www.phila.gov/media/20220525080608/tax-year-2023-mass-appraisal-valuation-methodology.pdf
          mutate(number_of_rooms = ifelse(is.na(number_of_rooms), 1, number_of_rooms))


data <- data[phl, ]
keep_columns <- sapply(data, function(col) length(unique(col)) > 1) #drop columns with only one unique value (i.e., no variance)
data <- data[, keep_columns]

### neighborhoods-----------------------------------------------
hoods_path <- 'https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson'
hoods <- st_read(hoods_path, quiet = T) %>%
  st_transform(crs = crs) %>%
  select(mapname)

data <- st_join(data, hoods)

### ACS-----------------------------------------------
phl_acs <- readRDS("phl_acs.RData")
data <- st_join(data, phl_acs)

### tree canopy cover-----------------------------------------------
# url <- "https://national-tes-data-share.s3.amazonaws.com/national_tes_share/pa.zip.zip"
# tmp_file <- tempfile(fileext = ".zip")
# curl_download(url, tmp_file)
# 
# unzipped_folder_1 <- tempfile()
# unzip(tmp_file, exdir = unzipped_folder_1)
# shp_files <- list.files(unzipped_folder_1, pattern = "\\.shp$", recursive = TRUE, full.names = TRUE)
# tree_canopy_gap <- st_read(shp_files[1], quiet = TRUE)  # assuming there's only one .shp file
# phl_tree_canopy <- tree_canopy_gap %>%
#   filter(state == "PA",
#          county == "Philadelphia County") %>%
#   transmute(tree_cover = 1 - tc_gap) %>%
#   st_transform(crs = crs)
# 
# data <- st_join(data, phl_tree_canopy)

### spatial lag of sale price-----------------------------------------------
data <- data %>% 
          mutate(nb = st_knn(geometry, k = 15),
                 wt = st_weights(nb),
                 price_lag = st_lag(sale_price, nb, wt)) %>%
          select(-c(nb, wt))

### proximity to commmercial corridors-----------------------------------------------
corridors_path <- "https://opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson"
corridors <- st_read(corridors_path, quiet= TRUE) %>% st_transform(crs = crs)

nearest_fts <- sf::st_nearest_feature(data, corridors)

# convert to rsgeo geometries
x <- rsgeo::as_rsgeo(data)
y <- rsgeo::as_rsgeo(corridors)

# calculate distance
data$dist_to_commerce <- rsgeo::distance_euclidean_pairwise(x, y[nearest_fts])

### proximity to downtown-----------------------------------------------
downtown <- st_sfc(st_point(c(-75.16408, 39.95266)), crs = 4326)
downtown_sf <- st_sf(geometry = downtown)
downtown_sf <- downtown_sf %>% st_transform(crs= crs)

nearest_fts <- sf::st_nearest_feature(data, downtown_sf)

# convert to rsgeo geometries
x <- rsgeo::as_rsgeo(data)
y <- rsgeo::as_rsgeo(downtown_sf)

# calculate distance
data$dist_to_downtown <- rsgeo::distance_euclidean_pairwise(x, y[nearest_fts])

### shootings density-----------------------------------------------
shootings_url <- 'https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+shootings+WHERE+year+%3E+2022&filename=shootings&format=geojson&skipfields=cartodb_id'
shootings <- st_read(shootings_url, quiet = TRUE) %>% 
                  st_transform(crs = crs) %>%
                  filter(!st_is_empty(geometry))

sp_points <- as(shootings, "Spatial")
ppp_object <- as.ppp(sp_points)
kde <- densityAdaptiveKernel(ppp_object)
kde_spatraster <- rast(kde)

guncrime <- terra::extract(kde_spatraster, data) %>%
              transmute(ID = ID,
                        guncrime_density = scale(lyr.1))

data <- cbind(data, guncrime) 
```

### OLS Model
```{r ols model}
numeric_only <- data %>% st_drop_geometry() %>% select(where(is.numeric)) 
model <- lm(sale_price ~ ., data = numeric_only)
keep_vars <- c(ols_step_both_aic(model)$predictors, "sale_price", "mapname", "building_code_description_new", "quality_grade")

final_data <- data %>% select(all_of(keep_vars)) %>% st_drop_geometry()

dummied_data <- dummy_cols(final_data) %>%
                    clean_names() %>%
                    select(-c(mapname,
                              building_code_description_new,
                              quality_grade))

model <- lm(sale_price ~ ., data = dummied_data)
stepwise_selection <- ols_step_both_aic(model)
print(stepwise_selection)
keep_vars <- c(stepwise_selection$predictors, "sale_price")

final_data <- dummied_data %>% select(keep_vars) %>% st_drop_geometry()


customSummary <- function(data, lev = NULL, model = NULL) {
  mpe <- mean((data$obs - data$pred) / data$obs) * 100
  mae <- mean(abs(data$obs - data$pred))
  rmse <- sqrt(mean((data$obs - data$pred)^2))
  rsq <- cor(data$obs, data$pred)^2
  out <- c(MAE = mae, RMSE = rmse, Rsquared = rsq, MPE = mpe)
  out
}

train_control <- trainControl(method = "cv",
                              number = 100,
                              summaryFunction = customSummary)


model <- train(sale_price ~ ., 
               data = final_data,
               trControl = train_control,
               method = "lm",
               na.action = na.exclude)

print(model)
```
```{r mae hist}
ggplot(data = model$resample) +
  ggplot2::geom_histogram(aes(x = MAE)) +
  labs(title = "Distribution of MAE",
       subtitle = "K-Fold Cross Validation; k = 100",
       x = "Mean Absolute Error",
       y = "Count")
```

## Results

### Regression Results

### Spatial Autocorrelation and Error
```{r autocorr}
data_nb <- data %>% 
          mutate(nb = st_knn(geometry, k = 5),
                 wt = st_weights(nb),
                 .before = 1)


# calculate global moran's i for sale_price
global_moran(data_nb$sale_price, data_nb$nb, data_nb$wt)$`I`

# moran monte carlo
moranMC = global_moran_perm(data_nb$sale_price, data_nb$nb, data_nb$wt, alternative = "two.sided", 999)
moranMC

moranMCres = moranMC$res |>
  as.data.frame()

colnames(moranMCres) = "col1"

ggplot(moranMCres) +
  geom_histogram(aes(col1), bins = 100) +
  geom_vline(xintercept = moranMC$statistic, col = "red") +
  labs(title = "Histogram of MoranMCres",
       x = "moranMCres",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

moran.plot(data_nb$sale_price, nb2listw(data_nb$nb),
           xlab = "Sale Price", 
           ylab = "Spatial Lag")
```

```{r resids}
reg <- lm(sale_price ~ ., 
               data = final_data,
          na.action = na.exclude)

reg_data <- cbind(reg$model, 
                  reg$residuals, 
                  reg$fitted.values) %>%
              mutate(resids = `reg$residuals`,
                     pred_value = `reg$fitted.values`)

ggplot(reg_data) +
    ggplot2::geom_point(aes(x = sale_price, y = pred_value), alpha = 0.5) +
    ggplot2::geom_abline() +
    theme_minimal()

# mean(reg_data$resids)
# 
# 
# join_cols <- c("sale_price",
#                "off_street_open",
#                "medRent",
#                "pctWhite")
# final_data_cols <- names(dummied_data)
# spat_data <- data %>% select(final_data_cols) %>% na.omit()
#   
# reg_data <- inner_join(reg_data, spat_data, by = c("sale_price" = "sale_price",
#                                                    "off_street_open" = "off_street_open",
#                                                    "med_rent" = "medRent",
#                                                    "pct_white" = "pctWhite"))
# 
# reg_data <- inner_join()
# reg_data$residuals <- reg$residuals
# 
# reg_data <- final_data %>%
#               transmute(
#                stand_resids = rstandard(reg),
#                      spatial_lag = st_lag(stand_resids, 
#                                              nb, 
#                                              weights)
#               )
```

```{r lisa map}
lisa = local_moran(data_nb$sale_price, data_nb$nb, data_nb$wt, nsim = 999)
data_nb <- cbind(data_nb, lisa)

lisa_sample <- sample_n(data_nb, 100)

tmap_mode('view')

tm_shape(lisa_sample) +
  tm_dots(col = "p_ii")
```

## Discussion

### Accuracy and Generalizability

## Conclusion


